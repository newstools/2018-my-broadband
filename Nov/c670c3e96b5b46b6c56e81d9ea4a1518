Facebook Inc. said it has removed 3 million posts related to terrorism in the third quarter, down from 9.4 million pieces in the second quarter, much of which was identified by specialized machine-learning tools that spot the content quicker than before. The social media company said improvements it has made to its technical tools helped it find and remove terrorist content. Such material reported by users in the third quarter remained on the platform for 18 hours before it was eliminated, down from 43 hours before it was taken down in the first quarter, Facebook said Thursday in a blog post. Facebook said 99 percent of terrorist content from ISIS and al-Qaeda was removed by the company itself before it was reported by anyone in the community. “We still rely on specialized reviewers to evaluate most posts, and only immediately remove posts when the tool’s confidence level is high enough that its ‘decision’ indicates it will be more accurate than our human reviewers,” the company said.