The Ultra HD Forum has released version 1.0 of its Phase B Guidelines for UHD implementation. UHD – ultra-high definition – TVs are growing in popularity around the world, as broadcasters and streaming services serve more UHD/4K content. The point of the guidelines is to help “the industry navigate the complex UHD landscape”, said the organisation. “UHD Phase B Guidelines introduce and demystify next-generation UHD technologies that operators are exploring for future enhanced UHD services,” it said. The technologies covered by the new guidelines include: The forum stated that it is focusing on two HDR metadata systems – Dolby Vision and SL-HDR. Dolby Vision is an ecosystem solution that utilises dynamic HDR metadata to create, distribute, and render HDR content, it said. It also “preserves artistic intent across a wide variety of distribution systems and displays”. SL-HDR is a method of down-conversion to derive an SDR/BT.709 signal from an HDR/WCG signal. “SL-HDR dynamic HDR metadata contains the necessary information to reconstruct the HDR/WCG signal. It supports PQ, HLG, and other HDR/WCG formats,” said the forum.  The guidelines also touched on improved viewer experiences and higher frame rates for content. It stated that new 4K high frame rates “would exceed the capabilities of some portions of the end-to-end ecosystem”, however. “For example, while HDMI 2.1 supports 4K 120fps or 8K 60fps, most production environment transport systems currently support only 2K with 100/120 fps.” While this may change in the future, the forum describes high frame rate with 2K spatial resolution for its Phase B guidelines. The parameters are: “Next-generation audio” will compliment and complete the UHD visual experience, said the forum. The new audio features include: This will be made possible thanks to Dolby AC-4 and MPEG-H Audio. MPEG-H Audio “efficiently carries any combination of channel, object, and scene-based signals”, and includes Higher Order Ambisonics, said the forum. “Each produced signal channel is part of an overall description of the entire sound scene, independent of the number and locations of loudspeakers.” Metadata also enables rendering, advanced loudness control, personalisation and interactivity, and dialog enhancement, it said. It stated that Dolby AC-4 also carries channel-based and object-based audio elements, or a combination of the two.  The overview of the Phase B guidelines concluded with a section on content-aware encoding, or content-adaptive encoding (CAE). This is a class of techniques for improving coding efficiency, said the forum. It intelligently exploits properties of the content to reduce bitrate, with “simple” content – such as scenes with little motion – encoded using fewer bits. “Complex” content, such as high-motion scenes, is then encoded using the necessary bits for quality reproduction. “Since simple content is prevalent, the use of CAE techniques can result in significant bandwidth savings.”