Amazon.com Inc. in June pitched its facial recognition technology — which can identify people from surveillance footage using image databases — as a tool for U.S. Immigration and Customs Enforcement, showing that Amazon continued to push the software to law enforcement agencies as criticism swirled from the company’s workforce and civil liberties groups. Employees in the Amazon Web Services cloud-computing unit met with the federal agency in California to present its artificial intelligence tools, according to emails obtained by the nonprofit Project on Government Oversight. Those tools include Rekognition, which uses artificial intelligence to quickly identify people in photos and videos. The software enables law enforcement to track individuals from cameras in public places. The American Civil Liberties Union in May criticized the use of the technology by police departments in Oregon and Florida, saying it threatened civil rights. News that the technology is being considered by federal immigration officials was reported earlier Tuesday by The Daily Beast. Amazon shared details about Rekognition and other tools at a “boot camp” sponsored by McKinsey & Co. and attended by other technology companies, an Amazon spokeswoman said in a statement. “As we usually do, we followed up with customers who were interested in learning more about how to use our services,” the spokeswoman said. “Immigration and Customs Enforcement was one of those organizations where there was follow-up discussion.” ICE has no current contract with Amazon, agency spokesman Matthew Bourke wrote in an email. The agency regularly meets with vendors to learn more about the tools they are offering, he said. “ICE’s Homeland Security Investigations has used facial recognition in the past to assist during the course of criminal investigations related to fraudulent activities, identity theft and child exploitation crimes, and the component will continue to explore cutting-edge technology to compliment criminal investigations going forward,” Bourke said. Law enforcement has made wide use of facial recognition for a range of tasks, from comparing mug shots with databases of drivers’ license photos to scanning of people walking by surveillance cameras. Some artificial intelligence software used for facial recognition has been shown to be racially biased because it was trained with relatively few minority images. In an infamous example from 2015, Google’s AI-powered photo-tagging system classified some black people as gorillas. In a paper published this year, researchers at the Massachusetts Institute of Technology and Microsoft Corp. found that facial-recognition systems are far less accurate at identifying non-white people and women than white men. In 2016, researchers at Georgetown University found that at least five major police departments claimed to run real-time face recognition on footage from street cameras, or expressed interesting in doing so. The use of artificial intelligence tools by government has divided the tech industry. Alphabet Inc. responded to employee protests about its contracts with the military by releasing a set of principles to guide the contracts it would pursue that use its artificial intelligence tools. It also won’t renew a Pentagon contract to use Google AI to analyze drone video footage. Amazon Chief Executive Officer Jeff Bezos said earlier this month that his company will “continue to support” the U.S. Defense Department, drawing a contrast with Google.